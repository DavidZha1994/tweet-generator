{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b93c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available? False\n"
     ]
    }
   ],
   "source": [
    "# Dennis' email on 29.April.2022\n",
    "\n",
    "#To summarize what was said in the meeting, you should start by implementing three different types of RNNs from scratch (basic RNN, GRU and LSTM) and testing them to see if your implementation is correct (torch.allclose()) is a good function to know for testing). Another thing you should do early on is pick some dataset and look how to #load it, tokenize the text, and transform them to tensors (look at Pytorch DataLoader and Dataset and other data #processing tools in pytorch first).\n",
    "#If you haven't done so yet, also watch the Stanford NLP lectures mentioned on the slides.\n",
    "\n",
    "\n",
    "# Installing Python Packages from Jupyter Notebook\n",
    "\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install <package name>\n",
    "\n",
    "\n",
    "# Package Settings\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import timeit\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Device configuration\n",
    "print(\"cuda is available? \" + str(torch.cuda.is_available()))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bebc3896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "\"\"\"\n",
    "sequence_length = 28\n",
    "input_size = 1\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "num_classes = 1\n",
    "batch_size = 100\n",
    "num_epochs = 2\n",
    "learning_rate = 0.001\n",
    "\"\"\"\n",
    "\n",
    "# Define RNN\n",
    "class TweetGenerator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(TweetGenerator, self).__init__()\n",
    "\n",
    "        # identiy matrix for generating one-hot vectors\n",
    "        self.ident = torch.eye(input_size)\n",
    "\n",
    "        # recurrent neural network\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size, \n",
    "            hidden_size, \n",
    "            n_layers, \n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # FC layer as decoder to the output\n",
    "        self.fc = nn.Linear(hidden_size, input_size)\n",
    "    \n",
    "    def forward(self, x, h_state=None):\n",
    "        x = self.ident[x]                  # generate one-hot vectors of input\n",
    "        output, h_state = self.rnn(x, h_state) # get the next output and hidden state\n",
    "        output = self.fc(output)          # predict distribution over next tokens\n",
    "        return output, h_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc32f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:\n",
      "['c', 'w', 'L', 'X', 'x', '/', 'y', 'm', 'e', 's', 'J', 'B', 'h', '!', 'n', 'l', '.', ':', 'o', 'Z', 'r', 'O', 'd', 't', ' ', 'i', 'p', 'a', 'g', '9', '<BOS>', '<EOS>']\n",
      "after:\n",
      "['<BOS>', 'O', 'l', 'y', 'm', 'p', 'i', 'c', 's', ' ', 'o', 'p', 'e', 'n', 'i', 'n', 'g', ' ', 'i', 's', ' ', 'e', 'x', 'c', 'e', 'l', 'l', 'e', 'n', 't', 'l', 'y', ' ', 'B', 'r', 'i', 't', 'i', 's', 'h', '.', ' ', 'J', 'o', 'l', 'l', 'y', ' ', 'g', 'o', 'o', 'd', ' ', 's', 'h', 'o', 'w', '!', ' ', ' ', 'h', 't', 't', 'p', ':', '/', '/', 't', '.', 'c', 'o', '/', 's', '9', 'X', 'Z', 'd', 'a', 'B', 'L', '<EOS>']\n",
      "TweetGenerator(\n",
      "  (rnn): RNN(32, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=32, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# .csv Dataset\n",
    "tweets = list(line[7] for line in csv.reader(open('dataset/2012.csv')))\n",
    "tweet = tweets[100]\n",
    "#print(tweet)\n",
    "\n",
    "# mae a vocabulary\n",
    "# torchtext has two schemes: stoi, itos\n",
    "vocab = list(set(tweet)) + [\"<BOS>\", \"<EOS>\"]\n",
    "vocab_stoi = {s: i for i, s in enumerate(vocab)}\n",
    "vocab_itos = {i: s for i, s in enumerate(vocab)}\n",
    "vocab_size = len(vocab)\n",
    "print('before:')\n",
    "print(vocab)\n",
    "tweet_ch = [\"<BOS>\"] + list(tweet) + [\"<EOS>\"]\n",
    "tweet_indices = [vocab_stoi[ch] for ch in tweet_ch]\n",
    "tweet_tensor = torch.Tensor(tweet_indices).long().unsqueeze(0)\n",
    "print('after:')\n",
    "print(tweet_ch)\n",
    "#bos_input = torch.Tensor([vocab_stoi[\"<BOS>\"]]).long().unsqueeze(0)\n",
    "\n",
    "#target = torch.Tensor([vocab_stoi[\"<EOS>\"]]).long().unsqueeze(0)\n",
    "target = tweet_tensor[:,1:]  \n",
    "model = TweetGenerator(vocab_size, hidden_size=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b88ff496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Starting]\n",
      "[Iter 50] Loss 0.002642\n",
      "[Iter 100] Loss 0.001129\n",
      "[Iter 150] Loss 0.000655\n",
      "[Iter 200] Loss 0.000434\n",
      "[Iter 250] Loss 0.000312\n",
      "[Iter 300] Loss 0.000236\n",
      "[Done]\n",
      "[Runtime]  1.7179921190000016\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "print('[Starting]')\n",
    "start = timeit.default_timer()\n",
    "for it in range(300):\n",
    "    optimizer.zero_grad()\n",
    "    output, _ = model(tweet_tensor[:,:-1])\n",
    "    loss = loss_func(output.reshape(-1, vocab_size),\n",
    "                 target.reshape(-1))\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    if (it+1) % 50 == 0:\n",
    "        print(\"[Iter %d] Loss %f\" % (it+1, float(loss)))\n",
    "stop = timeit.default_timer()\n",
    "print('[Done]')\n",
    "print('[Runtime] ', stop-start)\n",
    "\n",
    "# Save the model checkpoint\n",
    "#torch.save(model.state_dict(), 'rnn-model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6687367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
